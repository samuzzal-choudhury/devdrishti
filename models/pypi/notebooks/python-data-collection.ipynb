{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "\n",
    "Gather all requirements.txt files from repositories having python as language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "job = bigquery.job.QueryJobConfig()\n",
    "job.use_legacy_sql = True\n",
    "client = bigquery.Client(default_query_job_config=job)\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    " SELECT D.id AS id,\n",
    "       repo_name,\n",
    "       path,\n",
    "       content\n",
    "FROM   (SELECT id,\n",
    "               content\n",
    "        FROM   [bigquery-public-data.github_repos.contents]\n",
    "        GROUP  BY id,\n",
    "                  content) AS D\n",
    "       INNER JOIN (SELECT id,\n",
    "                          C.repo_name AS repo_name,\n",
    "                          path\n",
    "                   FROM   (SELECT id,\n",
    "                                  repo_name,\n",
    "                                  path\n",
    "                           FROM\n",
    "                  [bigquery-public-data:github_repos.files]\n",
    "                           WHERE  LOWER(path) LIKE '%requirements.txt'\n",
    "                           GROUP  BY path,\n",
    "                                     id,\n",
    "                                     repo_name) AS C\n",
    "                          INNER JOIN (SELECT repo_name,\n",
    "                                             language.name\n",
    "                                      FROM\n",
    "                          [bigquery-public-data.github_repos.languages]\n",
    "                                      WHERE  LOWER(language.name) LIKE\n",
    "                                             '%python%'\n",
    "                                      GROUP  BY language.name,\n",
    "                                                repo_name) AS F\n",
    "                                  ON C.repo_name = F.repo_name) AS E\n",
    "               ON E.id = D.id  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the collected data in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "for row in query_job:\n",
    "    content = {\n",
    "        \"id\": row.get('id'),\n",
    "        \"repo_name\": row.get('repo_name'),\n",
    "        \"path\": row.get(\"path\"),\n",
    "        \"content\": row.get('content')\n",
    "    }\n",
    "    content_list.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('python-bigquery-data.json', 'w') as f:\n",
    "    json.dump(content_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take out all requirements.txt contents out of the stored json and dump them in a single requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('requirements.txt', 'a') as r, open('python-bigquery-data.json', 'r')  as f:\n",
    "    content = json.load(f)\n",
    "    for x in content:\n",
    "        if x.get('content'):\n",
    "            r.write(x.get('content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Filtering\n",
    "\n",
    "This is the trickiest part. We do the following:\n",
    "\n",
    "- We iterate through every requirements.txt file and dump the contents in a temp file.\n",
    "- After that, we check if it's a valid requirements.txt file.\n",
    "- Then we check if the package name is a valid package name after querying it on pypi.\n",
    "\n",
    "We create a json file to store all the valid manifests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pip._internal.req.req_file import parse_requirements\n",
    "from pip._internal.download import PipSession\n",
    "import requests\n",
    "import requests_cache\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pip._vendor.distlib.util import normalize_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_cache.install_cache(expire_after=timedelta(hours=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_json = [{\n",
    "    \"ecosystem\": \"pypi\",\n",
    "    \"package_list\": []\n",
    "}]\n",
    "session = PipSession()\n",
    "\n",
    "with open(\"python-bigquery-data.json\", \"r\") as f, open('error-log-pip.txt', 'a') as log:\n",
    "    content = json.load(f)\n",
    "    for x in content:\n",
    "        if x.get('content'):\n",
    "            with open(\"temp-requirements.txt\", \"w\") as w:\n",
    "                w.write(x.get('content'))\n",
    "            req_names = []\n",
    "            try:\n",
    "                for p in parse_requirements(\"temp-requirements.txt\", session=session):\n",
    "                    if p.name:\n",
    "                        name = normalize_name(p.name)\n",
    "                        r = requests.get(url='https://pypi.org/pypi/{}/json'.format(name), headers={\"Accept\": \"application/json\"})\n",
    "                        if r.status_code == 200:\n",
    "                            print(\"Package: {} done\".format(name))\n",
    "                            req_names.append(name)\n",
    "            except Exception as e:\n",
    "                log.write(e)\n",
    "            manifest_json[0].get(\"package_list\").append(req_names)\n",
    "                    \n",
    "# for p in parse_requirements(\"requirements-final.txt\", session=PipSession()):\n",
    "#     print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_json[0].get(\"package_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"manifest-list-with-pip-api-normalized.json\", \"w\") as w:\n",
    "    json.dump(manifest_json, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We filter the data further by keeping only manifests with length > 0 and removing duplicate manifests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_json = [{\n",
    "    \"ecosystem\": \"pypi\",\n",
    "    \"package_list\": []\n",
    "}]\n",
    "\n",
    "with open('manifest-list-with-pip-api-normalized.json', 'r') as f:\n",
    "    content = json.load(f)\n",
    "    manifest_set = set()\n",
    "    for package_list in content[0].get('package_list'):\n",
    "        if len(package_list) > 0:\n",
    "            manifest_set.add(frozenset(package_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_json[0]['package_list'] = [list(x) for x in manifest_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manifest-list-trimmed-unique.json', 'w') as w:\n",
    "    json.dump(manifest_json, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
